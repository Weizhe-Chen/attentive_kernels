<!DOCTYPE html>
<html lang="en-us">
  
  <head>
  <meta charset="UTF-8">
  <title>AK: Attentive Kernel for Information Gathering</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#990000">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>


  <body>
    <section class="page-header">
  <img src="/assets/trident.png" width="100" height="100">
  <h1 class="project-name">AK: Attentive Kernel for Information Gathering</h1>
  <h2 class="project-tagline">Weizhe Chen, Roni Khardon, Lantao Liu</h2>
  <a href="https://arxiv.org/abs/2205.06426" class="btn">arXiv</a>
  <a href="https://github.com/weizhe-chen/attentive_kernels" class="btn">GitHub</a>
  <a href="https://github.com/weizhe-chen/attentive_kernels/zipball/master" class="btn">Download .zip</a>
  <a href="https://github.com/weizhe-chen/attentive_kernels/tarball/master" class="btn">Download .tar.gz</a>
</section>


    <section class="main-content">
      
      <h1 id="abstract">Abstract</h1>

<p>Robotic Information Gathering (RIG) relies on the uncertainty of a probabilistic model to identify critical areas for efficient data collection. Gaussian processes (GPs) with stationary kernels have been widely adopted for spatial modeling. However, real-world spatial data typically does not satisfy the assumption of stationarity, where different locations are assumed to have the same degree of variability. As a result, the prediction uncertainty does not accurately capture prediction error, limiting the success of RIG algorithms. We propose a novel family of nonstationary kernels, named the Attentive Kernel (AK), which is simple, robust, and can extend any existing kernel to a nonstationary one. We evaluate the new kernel in elevation mapping tasks, where AK provides better accuracy and uncertainty quantification over the commonly used RBF kernel and other popular nonstationary kernels. The improved uncertainty quantification guides the downstream RIG planner to collect more valuable data around the high-error area, further increasing prediction accuracy. A field experiment demonstrates that the proposed method can guide an Autonomous Surface Vehicle (ASV) to prioritize data collection in locations with high spatial variations, enabling the model to characterize the salient environmental features.</p>

<h1 id="field-experiment">Field Experiment</h1>
<p><a href="https://www.youtube.com/embed/qpoxSF5S9zk"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/field_experiment_cover.png" alt="drawing" width="100%" /></a></p>

<h1 id="simulated-experiments">Simulated Experiments</h1>

<h2 id="environment-n17e073">Environment: N17E073</h2>

<p><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/envs/N17E073.png" alt="drawing" width="60%" /></p>

<h3 id="attentive-kernel">Attentive Kernel</h3>

<p><a href="https://www.youtube.com/embed/P92J6NmZeK0"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N17E073_ak.png" alt="drawing" width="60%" /></a></p>

<h3 id="rbf-kernel">RBF Kernel</h3>

<p><a href="https://www.youtube.com/embed/_94lIe7usx8"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N17E073_rbf.png" alt="drawing" width="60%" /></a></p>

<h3 id="gibbs-kernel">Gibbs Kernel</h3>

<p><a href="https://www.youtube.com/embed/aZ5PXXW-94U"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N17E073_gibbs.png" alt="drawing" width="60%" /></a></p>

<h3 id="deep-kernel-learning">Deep Kernel Learning</h3>

<p><a href="https://www.youtube.com/embed/l3lNihEuoQU"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N17E073_dkl.png" alt="drawing" width="60%" /></a></p>

<h2 id="environment-n43w080">Environment: N43W080</h2>

<p><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/envs/N43W080.png" alt="drawing" width="60%" /></p>

<h3 id="attentive-kernel-1">Attentive Kernel</h3>

<p><a href="https://www.youtube.com/embed/_4oyuKxFBkY"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N43W080_ak.png" alt="drawing" width="60%" /></a></p>

<h3 id="rbf-kernel-1">RBF Kernel</h3>

<p><a href="https://www.youtube.com/embed/lx8haGg0aCI"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N43W080_rbf.png" alt="drawing" width="60%" /></a></p>

<h3 id="gibbs-kernel-1">Gibbs Kernel</h3>

<p><a href="https://www.youtube.com/embed/5yDTqPvQ9QM"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N43W080_gibbs.png" alt="drawing" width="60%" /></a></p>

<h3 id="deep-kernel-learning-1">Deep Kernel Learning</h3>

<p><a href="https://www.youtube.com/embed/ZK28mCQYVUQ"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N43W080_dkl.png" alt="drawing" width="60%" /></a></p>

<h2 id="environment-n45w123">Environment: N45W123</h2>

<p><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/envs/N45W123.png" alt="drawing" width="60%" /></p>

<h3 id="attentive-kernel-2">Attentive Kernel</h3>

<p><a href="https://www.youtube.com/embed/BtKDLO1asnk"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N45W123_ak.png" alt="drawing" width="60%" /></a></p>

<h3 id="rbf-kernel-2">RBF Kernel</h3>

<p><a href="https://www.youtube.com/embed/eegdZR_M_zs"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N45W123_rbf.png" alt="drawing" width="60%" /></a></p>

<h3 id="gibbs-kernel-2">Gibbs Kernel</h3>

<p><a href="https://www.youtube.com/embed/Z71hU4YbWs0"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N45W123_gibbs.png" alt="drawing" width="60%" /></a></p>

<h3 id="deep-kernel-learning-2">Deep Kernel Learning</h3>

<p><a href="https://www.youtube.com/embed/Qbk63_b2P1E"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N45W123_dkl.png" alt="drawing" width="60%" /></a></p>

<h2 id="environment-n47w124">Environment: N47W124</h2>

<p><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/envs/N47W124.png" alg="drawing" width="60%" /></p>

<h3 id="attentive-kernel-3">Attentive Kernel</h3>

<p><a href="https://www.youtube.com/embed/CC9St05e9Ow"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N47W124_ak.png" alt="drawing" width="60%" /></a></p>

<h3 id="rbf-kernel-3">RBF Kernel</h3>

<p><a href="https://www.youtube.com/embed/W1bnETwBtpI"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N47W124_rbf.png" alt="drawing" width="60%" /></a></p>

<h3 id="gibbs-kernel-3">Gibbs Kernel</h3>

<p><a href="https://www.youtube.com/embed/mqtxNkIv6bI"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N47W124_gibbs.png" alt="drawing" width="60%" /></a></p>

<h3 id="deep-kernel-learning-3">Deep Kernel Learning</h3>

<p><a href="https://www.youtube.com/embed/suYUdUDMzTE"><img src="https://raw.githubusercontent.com/Weizhe-Chen/attentive_kernels/gh-pages/assets/play_buttons/N47W124_dkl.png" alt="drawing" width="60%" /></a></p>


      <footer class="site-footer">
  <span class="site-footer-credits"><a href="https://vail.sice.indiana.edu/">VAIL: Vehicle Autonomy and Intelligence Lab</a></span>
  and
  <span class="site-footer-credits"><a href="https://cgi.luddy.indiana.edu/~rkhardon/index.php">Roni Khardon's Research Group</a></span>

</footer>


    </section>

  </body>
</html>
